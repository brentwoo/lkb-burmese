LING 567 - Lab 5
Brent Woo
===================

1. Statement of facts about language
2. Illustrative IGT examples
3. How implemented phenomena
=====================================


Modification
------------

Burmese has both types of modifiers. Adjectives are posthead, and adverbs are prehead.

This is added to rules.tdl:

head-adj-int := head-adj-int-phrase.
adj-head-int := adj-head-int-phrase.

In a sentence without a modifier the head-adj-phrase rule did not fire.

Adjectives
-----------

Adjectives follow the noun that they modify. There are certain adjectives, derived from verbs, that precede the nouns, but these are not treated in this lab.

Source: elicited
Vetted: t
Judgment: g
Phenomena: adj
einci ahaun apya can te
einci ahaun apya can te
shirt old blue remain RLS
`A blue old shirt remains.'

They should not precede the noun.

Source: elicited
Vetted: t
Judgment: u
Phenomena: adj
apya einci can te 
apya einci can te 
blue shirt remain RLS
`A blue shirt remains.'

In burmese.tdl, I added:

adjective-lex := basic-adjective-lex & intersective-mod-lex &
	      norm-ltop-lex-item &
  [ SYNSEM [ LOCAL [ CAT [ HEAD.MOD < [ LOCAL.CAT [ HEAD noun,
                                                    VAL.SPR cons ]]>,
			   VAL [ SPR < >,
				 SUBJ < >,
				 COMPS < >,
				 SPEC < > ],
			   POSTHEAD + ]]]].

With [POSTHEAD +] to indicate posthead adjectives.

I added some adjectives to the lexicon:

apya := adjective-lex &
  [ STEM < "apya" >,
    SYNSEM.LKEYS.KEYREL.PRED "_blue_a_rel" ].

I believe the adjective relations are being predicated of the right indices.


Adverbs
-------

I could only find examples where the adverbs preceded the verb:

Source: b:135
Vetted: s
Judgment: g
Phenomena: adv
ceno coucousasa ce me
ceno coucousasa ce me
I dilligently learn RLS
`I will dilligently learn.'

In burmese.tdl, I added:

adverb-lex := basic-adverb-lex & intersective-mod-lex &
  [ SYNSEM [ LOCAL [ CAT [ HEAD.MOD < [ LOCAL.CAT.HEAD verb ]>,
			   VAL [ SPR < >,
				 SUBJ < >,
				 COMPS < >,
				 SPEC < > ],
			   POSTHEAD - ]]]].

With [POSTHEAD -] to indicate prehead adverbs. I only have positive evidence for prehead adverbs, although I did not yet ask my speaker whether posthead adverbs were possible, I erred on the side of undergeneration. I would also like to get examples proving whether or not adverbs can intervene between verb, aux, and/or particles.

I added some adverbs to the lexicon:

sanitaca := adverb-lex &
  [ STEM < "sanitaca" >,
    SYNSEM.LKEYS.KEYREL.PRED "_systematically_adv_rel" ].


Adjective Agreement
-------------------

None.


Demonstrative determiners
--------------------------

The only determiners Burmese has is demonstrative determiners. These precede the noun. There are only two: di (proximal), hou (distal).

(I synthesized this example from smaller elicited ones to show both.)

Source: author
Vetted: f
Judgment: g
Phenomena: cogst
hou sitha di cou hse te
hou sitha di cou hse te
that soldier this rope pull RLS
`The soldier pulls this rope.'

They should not follow the noun:

Source: elicited
Vetted: t
Judgment: u
Phenomena: cogst
sitha cou hou hse te
sitha cou hou hse te
soldier rope that pull RLS
`That soldier pulls the rope.'

They are not allowed to be associated with names or pronouns. This as marked in the customization system, excluding the types of names and pronouns.

Source: author
Vetted: t
Judgment: u
Phenomena: det
di lwin ei te
di lwin ei te
this lwin sleeps RLS
`This Lwin sleeps.'

Source: author
Vetted: t
Judgment: u
Phenomena: det
di thu ei te
di thu ei te
this he sleeps RLS
`This he sleeps.'

I added this type hierarchy to burmese.tdl:

demonstrative_a_rel := predsort.
proximal+dem_a_rel := demonstrative_a_rel. ; close to speaker
distal+dem_a_rel := demonstrative_a_rel.   ; away from speaker
mid+dem_a_rel := distal+dem_a_rel.         ; away, but not very far away
far+dem_a_rel := distal+dem_a_rel.         ; very far away

but I will employ only the two types: proximal+dem_a_rel and distal+dem_a_rel. 

I added these two entries to lexicon.tdl:

di := determiner-lex-supertype &
  [ STEM < "di" >,
    SYNSEM.LKEYS.ALTKEYREL.PRED proximal+dem_a_rel ].

hou := determiner-lex-supertype &
  [ STEM < "hou" >,
    SYNSEM.LKEYS.ALTKEYREL.PRED distal+dem_a_rel ].

In order to get the semantics right, I added this type to burmese.tdl:

 determiner-lex-supertype := norm-hook-lex-item & basic-zero-arg &
  [ SYNSEM [ LOCAL [ CAT [ HEAD det,
			   VAL[ SPEC.FIRST.LOCAL.CONT.HOOK [ INDEX #ind,
							     INDEX.COG-ST activ+fam,
				  			     LTOP #larg ],
                                SPR < >,
                                SUBJ < >,
                                COMPS < >]],
		     CONT.HCONS < ! qeq &
				 [ HARG #harg,
				   LARG #larg ] ! >,
		     CONT.RELS <!  [ PRED "exist_q_rel" ], 
				 arg1-ev-relation & #altkeyrel & [LBL #larg, ARG1 #ind]  !> ], 
	     LKEYS.KEYREL quant-relation &
		   [ ARG0 #ind,
		     RSTR #harg ],
	     LKEYS.ALTKEYREL #altkeyrel]].

I added [COG-ST activ+fam] to reflect cognitive status. The relations list has two things on it, an exist_q_rel predication, and an arg1-ev-relation that links up LBL and ARG1 with the determiner's own LTOP and INDEX.

Argument optionality
------------------

I gathered that the Burmese facts reflect the Matrix defaults, w.r.t. optional arguments, especially since there is no marking or anything on the verb indicating that something has been dropped. Dropped subjects are assumed to be [COG-ST in-foc], and dropped objects are assumed to be [COG-ST activ-or-more].

This series of examples illustrates arg-opt. This first is the base case with all arguments:

Source: elicited
Vetted: t
Judgment: g
Phenomena: pro-d
di sitha cou hse te
di sitha cou hse te
this soldier rope pull RLS
`This soldier pulls the rope.'

Object dropped. Ambiguous:

Source: author
Vetted: f
Judgment: g
Phenomena: pro-d
di sitha hse te
di sitha hse te
this soldier pull RLS
`This soldier pulls () OR () pulls this soldier.'

Object dropped. Subject marked, so not ambiguous. (at the time of writing this doesn't parse but should. on the todo list)

Source: author
Vetted: f
Judgment: g
Phenomena: pro-d
di sitha ka hse te
di sitha ka hse te
this soldier SUBJ pull RLS
`This soldier pulls ().'

Subject dropped. Ambiguous.

Source: elicited
Vetted: t
Judgment: g
Phenomena: pro-d
cou hse te
cou hse te
rope pull RLS
`The rope pulls () OR () pulls the rope.'

Subject dropped. Object marked so not ambiguous. This one does parse as it should.

Source: elicited
Vetted: t
Judgment: g
Phenomena: pro-d
cou kou hse te
cou kou hse te
rope OBJ pull RLS
`The rope pulls () OR () pulls the rope.'


Other
-----

* All overt personal pronouns were constrained to be [INDEX [COG-ST activ-or-more, SPECI + ]]. Also, they were retyped so that first person pronouns now have [PER 1, NUM sg] features, etc. Also PRED fixed to pron_rel.

ceno := pron1-noun-lex &
  [ STEM < "ceno" >,
    SYNSEM.LKEYS.KEYREL.PRED "pron_rel",
    SYNSEM.LOCAL.CONT.HOOK.INDEX [COG-ST activ-or-more,
				SPECI + ] ].

* For the question particle, constraint on FORM was relaxed to allowed the Q particle to appear even without a sentence final particle.

qpart-lex-item := complementizer-lex-item &
  [ SYNSEM.LOCAL [ CONT.HOOK.INDEX.SF ques,
                   CAT.VAL.COMPS.FIRST.LOCAL.CAT.HEAD.FORM form ] ].

So simple sentences like this now parse:

Source: elicited
Vetted: t
Judgment: g
Phenomena: q
si hpyi la
si hpyi la
war happen RLS
`Does war happen?'

* Aux verb/sentence particles were incorrectly contributing PRED values and also qeq, got rid of those.


Misc
----

I think this is the longest sentence (which I made up) in the testsuite that parses successfully, showing several phenomena:

Source: a:260
Vetted: f
Judgment: g
Phenomena: wo
hou myeyeise athi ka di mye yain myin kou sanitaca hpya la
hou myeyeise athi ka di mye yain myin kou sanitaca hpya la
that lawnmower new SUBJ this grass wild tall OBJ systematically cut RLS
`That new lawnmower systematically cuts this tall wild grass?â€™


4. Problems
===========

* The sentence with dropped object and marked subject doesn't parse. 

di sitha ka hse te
this soldier SUBJ pull RLS
`This soldier pulls ().'

But the reverse -- dropped subject and marked object does:

cou kou hse te
rope OBJ pull RLS
`The rope pulls () OR () pulls the rope.'

* I'd like to add the entries to trigger.mtr to get rid of the annoying notification messages when a new grammar is loaded.

5. Statement of coverage
========================

165 total entries, 98 wellformed, 67 illformed (todo is more neg examples!)

* wellformed, analyzed: 39
* wellformed, unanalyzed: 23 -- many of these are sentences with the "zero copula", so simple NP-NP-aux or NP-ADJEC-aux sentences. Others have "true" auxiliaries (aspect) that I haven't addressed yet

* illformed, analyzed: 9 -- several examples are due to a complication from negation. special aux's have to be used when the sentence is negative. also, it seems like I did not sufficiently constrain adjectives, since the examples where adverbs are in any position in the sentence do parse but (I think) shouldn't.
* illformed, unanalyzed: 44

Coverage Profile:

ilengths	total items positive examples	overall coverage
10-15		3 			3 					100%
5-10		92			57 					31.6%
0-5			70 			38					47.4%
TOTAL 		165 		98 					39.8%

Overgeneration Profile:

ilengths 	total items negative 	overall coverage
10-15		3 			0 			0
5-10 		92 			35 			22.9
0-5 		70 			32 			3.1
TOTAL 		165 		67 			13.4

COMPARISONS

 			lexical	analyses 	in 	out
TOTAL OLD 	0.88	5.88 	35.2 	22.0
TOTAL NEW 	0.88	5.37 	39.8 	13.4

Corpus
=========

The text from the corpus is from Sealang.net (http://www.sealang.net/burmese/bitext.htm). The version I received with contiguous text isn't publically available, but was provided to me by my consultant who has access to the backend. 

It is an excerpt of a story about a man who got a new job in Burma. Some of the sentences are very complex, so I may choose to do a simpler story about a mom and daughter, in order to get even a little coverage. 

It's in standard format for make_item, but it has only the Burmese in Burmese script and an English translation. I have neither transliteration nor gloss available at the moment. I'll have to find some way to get the text transliterated, and I can gloss it using the sealang dictionary.

